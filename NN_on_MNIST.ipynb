{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMshLIBOw9+QOlBW1GGm8Yv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nitinmalviya326/deep-learning-lab/blob/main/NN_on_MNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "feQ8_RKTpLUI"
      },
      "outputs": [],
      "source": [
        "# Cell 1: Import libraries\n",
        "import numpy as np\n",
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# loading the MNIST dataset for handwritten digit classification\n",
        "# normalizing image pixel values to make training easier\n",
        "# converting labels to integers\n",
        "# splitting data into training and test sets for evaluation\n",
        "print(\"Loading data...\")\n",
        "X, y = fetch_openml('mnist_784', version=1, return_X_y=True, parser='auto')\n",
        "X = X.to_numpy() / 255.0\n",
        "y = y.to_numpy().astype(int)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "print(f\"Train: {len(X_train)}, Test: {len(X_test)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hSI8p4kzpc-w",
        "outputId": "50ad8d04-2d57-4fe7-dc87-2f959b0e5e45"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading data...\n",
            "Train: 56000, Test: 14000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# random seed is set to keep results consistent\n",
        "# weights are initialized with small random values\n",
        "# biases are initialized as zero vectors for each layer\n",
        "np.random.seed(42)\n",
        "W1 = np.random.randn(784, 128) * 0.01\n",
        "b1 = np.zeros((1, 128))\n",
        "W2 = np.random.randn(128, 10) * 0.01\n",
        "b2 = np.zeros((1, 10))"
      ],
      "metadata": {
        "id": "zw-oTBHypdLQ"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 4: Training dataset for 30 epocs with learning rate .1 nd batch size 128\n",
        "epochs = 30\n",
        "lr = 0.1\n",
        "batch_size = 128\n",
        "\n",
        "print(\"Training...\")\n",
        "for epoch in range(epochs):\n",
        "    indices = np.random.permutation(len(X_train))\n",
        "    X_train, y_train = X_train[indices], y_train[indices]\n",
        "\n",
        "    for i in range(0, len(X_train), batch_size):\n",
        "        X_batch = X_train[i:i+batch_size]\n",
        "        y_batch = y_train[i:i+batch_size]\n",
        "\n",
        "        # Forward forward propogation\n",
        "        a1 = np.maximum(0, X_batch @ W1 + b1)\n",
        "        z2 = a1 @ W2 + b2\n",
        "        a2 = np.exp(z2 - np.max(z2, axis=1, keepdims=True))\n",
        "        a2 = a2 / np.sum(a2, axis=1, keepdims=True)\n",
        "\n",
        "        # Backward propogation\n",
        "        dz2 = a2 - np.eye(10)[y_batch]\n",
        "        dW2 = a1.T @ dz2 / len(X_batch)\n",
        "        db2 = np.sum(dz2, axis=0, keepdims=True) / len(X_batch)\n",
        "        dz1 = (dz2 @ W2.T) * (a1 > 0)\n",
        "        dW1 = X_batch.T @ dz1 / len(X_batch)\n",
        "        db1 = np.sum(dz1, axis=0, keepdims=True) / len(X_batch)\n",
        "\n",
        "         # Update weights nd biases\n",
        "        W1 -= lr * dW1\n",
        "        b1 -= lr * db1\n",
        "        W2 -= lr * dW2\n",
        "        b2 -= lr * db2\n",
        "\n",
        "    #\n",
        "    a1 = np.maximum(0, X_train @ W1 + b1)\n",
        "    a2 = a1 @ W2 + b2\n",
        "    acc = np.mean(np.argmax(a2, axis=1) == y_train)\n",
        "    print(f\"Epoch {epoch+1}: {acc:.4f}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6TWsW-_xpdbU",
        "outputId": "52648146-5b8e-49ff-87d5-4643bcc7a5dc"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training...\n",
            "Epoch 1: 0.8980\n",
            "Epoch 2: 0.9184\n",
            "Epoch 3: 0.9317\n",
            "Epoch 4: 0.9402\n",
            "Epoch 5: 0.9493\n",
            "Epoch 6: 0.9540\n",
            "Epoch 7: 0.9577\n",
            "Epoch 8: 0.9628\n",
            "Epoch 9: 0.9669\n",
            "Epoch 10: 0.9696\n",
            "Epoch 11: 0.9719\n",
            "Epoch 12: 0.9736\n",
            "Epoch 13: 0.9762\n",
            "Epoch 14: 0.9764\n",
            "Epoch 15: 0.9791\n",
            "Epoch 16: 0.9809\n",
            "Epoch 17: 0.9813\n",
            "Epoch 18: 0.9826\n",
            "Epoch 19: 0.9833\n",
            "Epoch 20: 0.9845\n",
            "Epoch 21: 0.9861\n",
            "Epoch 22: 0.9867\n",
            "Epoch 23: 0.9869\n",
            "Epoch 24: 0.9873\n",
            "Epoch 25: 0.9886\n",
            "Epoch 26: 0.9891\n",
            "Epoch 27: 0.9896\n",
            "Epoch 28: 0.9902\n",
            "Epoch 29: 0.9895\n",
            "Epoch 30: 0.9921\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Cell 5: Test Accuracy (using softmax probabilities)\n",
        "\n",
        "z1 = X_test @ W1 + b1\n",
        "a1 = np.maximum(0, z1)\n",
        "\n",
        "z2 = a1 @ W2 + b2\n",
        "\n",
        "# softmax for probability distribution\n",
        "exp_scores = np.exp(z2 - np.max(z2, axis=1, keepdims=True))\n",
        "probs = exp_scores / np.sum(exp_scores, axis=1, keepdims=True)\n",
        "\n",
        "test_acc = np.mean(np.argmax(probs, axis=1) == y_test)\n",
        "print(f\"Test Accuracy: {test_acc:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C_0Enkg_rZJ9",
        "outputId": "cc2a9199-a481-43ab-97b9-3adff924ddc8"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.9734\n"
          ]
        }
      ]
    }
  ]
}